{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3318ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b028f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROCESS</th>\n",
       "      <th>IDENTIFIED DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>IDEN NO</th>\n",
       "      <th>AML TRANSANCTION NO</th>\n",
       "      <th>AML TYPE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>POLICY NO</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>MUSYA MUSYOKA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>10958863</td>\n",
       "      <td>21.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Automatic Fail</td>\n",
       "      <td></td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>RICHARD SIMIYU WANYAMA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-376</td>\n",
       "      <td>43.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>FRANCIS NJENGA KAMAU</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-388</td>\n",
       "      <td>44.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>ISAAC AHADI ELVIS</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>SID382369</td>\n",
       "      <td>113.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801443863</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>JAEDEN GEORGE</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>22258</td>\n",
       "      <td>114.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801437036</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PROCESS IDENTIFIED DATE                     NAME          TYPE  \\\n",
       "0  New Business      2018-06-12            MUSYA MUSYOKA  Life_Assured   \n",
       "1  New Business      2018-06-12  RICHARD SIMIYU WANYAMA   Life_Assured   \n",
       "2  New Business      2018-06-12    FRANCIS NJENGA KAMAU   Life_Assured   \n",
       "3  New Business      2018-06-13        ISAAC AHADI ELVIS   Beneficiary   \n",
       "4  New Business      2018-06-13            JAEDEN GEORGE   Beneficiary   \n",
       "\n",
       "          IDEN NO  AML TRANSANCTION NO AML TYPE                        STATUS  \\\n",
       "0        10958863                 21.0      AML                Automatic Fail   \n",
       "1  2018NEWSCB-376                 43.0      AML  Senior Officer Pass the case   \n",
       "2  2018NEWSCB-388                 44.0      AML  Senior Officer Pass the case   \n",
       "3       SID382369                113.0      AML  Senior Officer Pass the case   \n",
       "4           22258                114.0      AML  Senior Officer Pass the case   \n",
       "\n",
       "         POLICY NO                  Remarks  \n",
       "0                   Found At Date Of Birth,  \n",
       "1  GL201300996540   Found At Date Of Birth,  \n",
       "2  GL201300996540   Found At Date Of Birth,  \n",
       "3  IL201801443863           Found At Names,  \n",
       "4  IL201801437036           Found At Names,  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataset location\n",
    "filename = 'Fraud_Kenya.xlsx'\n",
    "\n",
    "# Load the Excel file as a DataFrame\n",
    "dataframe = pd.read_excel(filename)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dd0d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AML Type' column not found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Check if 'AML Type' column exists\n",
    "if 'AML Type' in data.columns:\n",
    "    # Convert 'AML Type' column to binary target variable\n",
    "    data['Fraud'] = data['AML Type'].apply(lambda x: 0 if 'AML' in x else 1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = data.drop(['AML Type', 'Fraud'], axis=1)\n",
    "    y = data['Fraud']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the deep learning model\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    # Save the model\n",
    "    model.save('fraud_detection_model.h5')\n",
    "else:\n",
    "    print(\"'AML Type' column not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c924b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROCESS</th>\n",
       "      <th>IDENTIFIED DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>IDEN NO</th>\n",
       "      <th>AML TRANSANCTION NO</th>\n",
       "      <th>AML TYPE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>POLICY NO</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>MUSYA MUSYOKA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>10958863</td>\n",
       "      <td>21.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Automatic Fail</td>\n",
       "      <td></td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>RICHARD SIMIYU WANYAMA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-376</td>\n",
       "      <td>43.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>FRANCIS NJENGA KAMAU</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-388</td>\n",
       "      <td>44.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>ISAAC AHADI ELVIS</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>SID382369</td>\n",
       "      <td>113.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801443863</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>JAEDEN GEORGE</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>22258</td>\n",
       "      <td>114.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801437036</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PROCESS IDENTIFIED DATE                     NAME          TYPE  \\\n",
       "0  New Business      2018-06-12            MUSYA MUSYOKA  Life_Assured   \n",
       "1  New Business      2018-06-12  RICHARD SIMIYU WANYAMA   Life_Assured   \n",
       "2  New Business      2018-06-12    FRANCIS NJENGA KAMAU   Life_Assured   \n",
       "3  New Business      2018-06-13        ISAAC AHADI ELVIS   Beneficiary   \n",
       "4  New Business      2018-06-13            JAEDEN GEORGE   Beneficiary   \n",
       "\n",
       "          IDEN NO  AML TRANSANCTION NO AML TYPE                        STATUS  \\\n",
       "0        10958863                 21.0      AML                Automatic Fail   \n",
       "1  2018NEWSCB-376                 43.0      AML  Senior Officer Pass the case   \n",
       "2  2018NEWSCB-388                 44.0      AML  Senior Officer Pass the case   \n",
       "3       SID382369                113.0      AML  Senior Officer Pass the case   \n",
       "4           22258                114.0      AML  Senior Officer Pass the case   \n",
       "\n",
       "         POLICY NO                  Remarks  \n",
       "0                   Found At Date Of Birth,  \n",
       "1  GL201300996540   Found At Date Of Birth,  \n",
       "2  GL201300996540   Found At Date Of Birth,  \n",
       "3  IL201801443863           Found At Names,  \n",
       "4  IL201801437036           Found At Names,  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b410d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       AML\n",
      "1                       AML\n",
      "2                       AML\n",
      "3                       AML\n",
      "4                       AML\n",
      "               ...         \n",
      "6927    SUSPIOUSTRANSACTION\n",
      "6928    SUSPIOUSTRANSACTION\n",
      "6929    SUSPIOUSTRANSACTION\n",
      "6930                    NaN\n",
      "6931                    NaN\n",
      "Name: AML TYPE, Length: 6932, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Display content in the 'AML TYPE' column\n",
    "print(data['AML TYPE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6183eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PROCESS IDENTIFIED DATE                     NAME          TYPE  \\\n",
      "0  New Business      2018-06-12            MUSYA MUSYOKA  Life_Assured   \n",
      "1  New Business      2018-06-12  RICHARD SIMIYU WANYAMA   Life_Assured   \n",
      "2  New Business      2018-06-12    FRANCIS NJENGA KAMAU   Life_Assured   \n",
      "3  New Business      2018-06-13        ISAAC AHADI ELVIS   Beneficiary   \n",
      "4  New Business      2018-06-13            JAEDEN GEORGE   Beneficiary   \n",
      "\n",
      "          IDEN NO  AML TRANSANCTION NO                        STATUS  \\\n",
      "0        10958863                 21.0                Automatic Fail   \n",
      "1  2018NEWSCB-376                 43.0  Senior Officer Pass the case   \n",
      "2  2018NEWSCB-388                 44.0  Senior Officer Pass the case   \n",
      "3       SID382369                113.0  Senior Officer Pass the case   \n",
      "4           22258                114.0  Senior Officer Pass the case   \n",
      "\n",
      "         POLICY NO                  Remarks  Fraud  \n",
      "0                   Found At Date Of Birth,      0  \n",
      "1  GL201300996540   Found At Date Of Birth,      0  \n",
      "2  GL201300996540   Found At Date Of Birth,      0  \n",
      "3  IL201801443863           Found At Names,      0  \n",
      "4  IL201801437036           Found At Names,      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop the 'AML TYPE' column\n",
    "data.drop(columns=['AML TYPE'], inplace=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5539628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROCESS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Business</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>Automatic Fail</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Business</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Business</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Business</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Business</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PROCESS          TYPE                        STATUS  \\\n",
       "0  New Business  Life_Assured                Automatic Fail   \n",
       "1  New Business  Life_Assured  Senior Officer Pass the case   \n",
       "2  New Business  Life_Assured  Senior Officer Pass the case   \n",
       "3  New Business   Beneficiary  Senior Officer Pass the case   \n",
       "4  New Business   Beneficiary  Senior Officer Pass the case   \n",
       "\n",
       "                   Remarks  \n",
       "0  Found At Date Of Birth,  \n",
       "1  Found At Date Of Birth,  \n",
       "2  Found At Date Of Birth,  \n",
       "3          Found At Names,  \n",
       "4          Found At Names,  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'IDENTIFIED DATE', 'NAME', \"AML TRANSANCTION NO\" ,'IDEN NO', 'POLICY NO'], inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the deep learning model\n",
    "#model = keras.Sequential([\n",
    " #   layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "  #  layers.Dense(64, activation='relu'),\n",
    "   # layers.Dense(1, activation='sigmoid')\n",
    "#])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "#loss, accuracy = model.evaluate(X_test, y_test)\n",
    "#print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "#model.save('fraud_detection_model.h5')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b704fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "174/174 [==============================] - 3s 11ms/step - loss: nan - accuracy: 0.1509 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1306 - val_loss: nan - val_accuracy: 0.1348\n",
      "44/44 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.1348\n",
      "Accuracy: 0.13482336699962616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks'], inplace=True)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the deep learning model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save('fraud_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23165555",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[0;32m    958\u001b[0m             array,\n\u001b[0;32m    959\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    960\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    961\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    123\u001b[0m     X,\n\u001b[0;32m    124\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    125\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    126\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    127\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    128\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    129\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks'], inplace=True)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'fraud_detection_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c67f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of       AML TRANSANCTION NO\n",
       "0                    21.0\n",
       "1                    43.0\n",
       "2                    44.0\n",
       "3                   113.0\n",
       "4                   114.0\n",
       "...                   ...\n",
       "6927              13365.0\n",
       "6928              13366.0\n",
       "6929              13367.0\n",
       "6930                  NaN\n",
       "6931                  NaN\n",
       "\n",
       "[6932 rows x 1 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f6b0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9105984138428262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fraud_detection_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks'], inplace=True)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Build the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'fraud_detection_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f74f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Score: 0.9226330027051398\n",
      "Accuracy: 0.9134823359769286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks'], inplace=True)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_rf.predict(X_test_imputed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91af7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9134823359769286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(columns=['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks'], inplace=True)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Define the best parameters obtained from grid search\n",
    "best_params = {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "\n",
    "# Create and train the Random Forest classifier with best parameters\n",
    "model = RandomForestClassifier(**best_params, random_state=42)\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "# joblib.dump(model, 'fraud_detection_model_best_params.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa8fa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROCESS</th>\n",
       "      <th>IDENTIFIED DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>IDEN NO</th>\n",
       "      <th>AML TRANSANCTION NO</th>\n",
       "      <th>AML TYPE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>POLICY NO</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>MUSYA MUSYOKA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>10958863</td>\n",
       "      <td>21.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Automatic Fail</td>\n",
       "      <td></td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>RICHARD SIMIYU WANYAMA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-376</td>\n",
       "      <td>43.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>FRANCIS NJENGA KAMAU</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>2018NEWSCB-388</td>\n",
       "      <td>44.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>GL201300996540</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>ISAAC AHADI ELVIS</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>SID382369</td>\n",
       "      <td>113.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801443863</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Business</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>JAEDEN GEORGE</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>22258</td>\n",
       "      <td>114.0</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>IL201801437036</td>\n",
       "      <td>Found At Names,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PROCESS IDENTIFIED DATE                     NAME          TYPE  \\\n",
       "0  New Business      2018-06-12            MUSYA MUSYOKA  Life_Assured   \n",
       "1  New Business      2018-06-12  RICHARD SIMIYU WANYAMA   Life_Assured   \n",
       "2  New Business      2018-06-12    FRANCIS NJENGA KAMAU   Life_Assured   \n",
       "3  New Business      2018-06-13        ISAAC AHADI ELVIS   Beneficiary   \n",
       "4  New Business      2018-06-13            JAEDEN GEORGE   Beneficiary   \n",
       "\n",
       "          IDEN NO  AML TRANSANCTION NO AML TYPE                        STATUS  \\\n",
       "0        10958863                 21.0      AML                Automatic Fail   \n",
       "1  2018NEWSCB-376                 43.0      AML  Senior Officer Pass the case   \n",
       "2  2018NEWSCB-388                 44.0      AML  Senior Officer Pass the case   \n",
       "3       SID382369                113.0      AML  Senior Officer Pass the case   \n",
       "4           22258                114.0      AML  Senior Officer Pass the case   \n",
       "\n",
       "         POLICY NO                  Remarks  \n",
       "0                   Found At Date Of Birth,  \n",
       "1  GL201300996540   Found At Date Of Birth,  \n",
       "2  GL201300996540   Found At Date Of Birth,  \n",
       "3  IL201801443863           Found At Names,  \n",
       "4  IL201801437036           Found At Names,  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4b7843d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['datetime', 'float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    172\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 174\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(uniques_set)\n\u001b[0;32m    175\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'datetime.datetime' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m         data[column] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(data[column])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Split the data into features (X) and target variable (y)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m X \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAML TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROCESS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDENTIFIED DATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDEN NO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLICY NO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemarks\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:115\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Encoded labels.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_python(\n\u001b[0;32m     43\u001b[0m         values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[0;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['datetime', 'float', 'str']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data[['AML TYPE', 'PROCESS', 'IDENTIFIED DATE', 'NAME', 'TYPE', 'IDEN NO', 'STATUS', 'POLICY NO', 'Remarks']]\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Define the best parameters obtained from grid search\n",
    "best_params = {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "\n",
    "# Create and train the Random Forest classifier with best parameters\n",
    "model = RandomForestClassifier(**best_params, random_state=42)\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "# joblib.dump(model, 'fraud_detection_model_best_params.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3119d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20a9ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6932 entries, 0 to 6931\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   PROCESS   6819 non-null   object\n",
      " 1   NAME      6930 non-null   object\n",
      " 2   TYPE      6930 non-null   object\n",
      " 3   AML TYPE  6930 non-null   object\n",
      " 4   STATUS    6929 non-null   object\n",
      " 5   Remarks   6930 non-null   object\n",
      " 6   Fraud     6932 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 379.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "data.drop(columns=['IDENTIFIED DATE', 'AML TRANSANCTION NO','IDEN NO','POLICY NO'], inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90a7f294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROCESS</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>AML TYPE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Business</td>\n",
       "      <td>MUSYA MUSYOKA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>AML</td>\n",
       "      <td>Automatic Fail</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Business</td>\n",
       "      <td>RICHARD SIMIYU WANYAMA</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Business</td>\n",
       "      <td>FRANCIS NJENGA KAMAU</td>\n",
       "      <td>Life_Assured</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Date Of Birth,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Business</td>\n",
       "      <td>ISAAC AHADI ELVIS</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Names,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Business</td>\n",
       "      <td>JAEDEN GEORGE</td>\n",
       "      <td>Beneficiary</td>\n",
       "      <td>AML</td>\n",
       "      <td>Senior Officer Pass the case</td>\n",
       "      <td>Found At Names,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PROCESS                     NAME          TYPE AML TYPE  \\\n",
       "0  New Business            MUSYA MUSYOKA  Life_Assured      AML   \n",
       "1  New Business  RICHARD SIMIYU WANYAMA   Life_Assured      AML   \n",
       "2  New Business    FRANCIS NJENGA KAMAU   Life_Assured      AML   \n",
       "3  New Business        ISAAC AHADI ELVIS   Beneficiary      AML   \n",
       "4  New Business            JAEDEN GEORGE   Beneficiary      AML   \n",
       "\n",
       "                         STATUS                  Remarks  Fraud  \n",
       "0                Automatic Fail  Found At Date Of Birth,      0  \n",
       "1  Senior Officer Pass the case  Found At Date Of Birth,      0  \n",
       "2  Senior Officer Pass the case  Found At Date Of Birth,      0  \n",
       "3  Senior Officer Pass the case          Found At Names,      0  \n",
       "4  Senior Officer Pass the case          Found At Names,      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2184592",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['datetime', 'float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    172\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 174\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(uniques_set)\n\u001b[0;32m    175\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'datetime.datetime' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m clean_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_data[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m         clean_data[column] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(clean_data[column])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Split the data into features (X) and target variable (y)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m X \u001b[38;5;241m=\u001b[39m data[[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROCESS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemarks\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:115\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Encoded labels.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_python(\n\u001b[0;32m     43\u001b[0m         values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[0;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['datetime', 'float', 'str']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Fraud_Kenya.xlsx', sheet_name='Sheet1')\n",
    "clean_data = data[[ 'PROCESS', 'NAME', 'TYPE', 'STATUS', 'Remarks']]\n",
    "# Create new column 'Fraud' based on 'AML TYPE' values\n",
    "data['Fraud'] = data['AML TYPE'].apply(lambda x: 0 if x == 'AML' else 1)\n",
    "\n",
    "# Label encode non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in clean_data.columns:\n",
    "    if clean_data[column].dtype == 'object':\n",
    "        clean_data[column] = label_encoder.fit_transform(clean_data[column])\n",
    "        \n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data[[ 'PROCESS', 'NAME', 'TYPE', 'STATUS', 'Remarks']]\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Define the best parameters obtained from grid search\n",
    "best_params = {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "\n",
    "# Create and train the Random Forest classifier with best parameters\n",
    "model = RandomForestClassifier(**best_params, random_state=42)\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Save the model\n",
    "# joblib.dump(model, 'fraud_detection_model_best_params.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b94953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
